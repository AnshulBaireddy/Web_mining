{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6: Clustering, Topic Modeling, Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you'll practice different text clustering methods. A dataset has been prepared for you:\n",
    "- `hw6_train.csv`: This file contains a list of documents. It's used for training models\n",
    "- `hw6_test`: This file contains a list of documents and their ground-truth labels (4 lables: 1,2,3,7). It's used for external evaluation. \n",
    "\n",
    "|Text| Label|\n",
    "|----|-------|\n",
    "|paraglider collides with hot air balloon ... | 1|\n",
    "|faa issues fire warning for lithium ... | 2|\n",
    "| .... |...|\n",
    "\n",
    "Sample outputs have been provided to you. Due to randomness, you may not get the same result as shown here. Your taget is to achieve about 70% F1 for the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: K-Mean Clustering \n",
    "\n",
    "Define a function `cluster_kmean(train_text, test_text, text_label)` as follows:\n",
    "- Take three inputs: \n",
    "    - `train_text` is a list of documents for traing \n",
    "    - `test_text` is a list of documents for test\n",
    "    - `test_label` is the labels corresponding to documents in `test_text` \n",
    "- First generate `TFIDF` weights. You need to decide appropriate values for parameters such as `stopwords` and `min_df`:\n",
    "    - Keep or remove stopwords? Customized stop words? \n",
    "    - Set appropriate `min_df` to filter infrequent words\n",
    "- Use `KMeans` to cluster documents in `train_text` into 4 clusters. Here you need to decide the following parameters:\n",
    "    \n",
    "    - Distance measure: `cosine similarity`  or `Euclidean distance`? Pick the one which gives you better performance.  \n",
    "    - When clustering, be sure to  use sufficient iterations with different initial centroids to make sure clustering converge.\n",
    "- Test the clustering model performance using `test_label` as follows: \n",
    "  - Predict the cluster ID for each document in `test_text`.\n",
    "  - Apply `majority vote` rule to dynamically map the predicted cluster IDs to `test_label`. Note, you'd better not hardcode the mapping, because cluster IDs may be assigned differently in each run. (hint: if you use pandas, look for `idxmax` function).\n",
    "  - print out the classification report for the test subset \n",
    "  \n",
    "  \n",
    "- This function has no return. Print out the classification report. \n",
    "\n",
    "\n",
    "- Briefly discuss:\n",
    "    - Which distance measure is better and why it is better. \n",
    "    - Could you assign a meaningful name to each cluster? Discuss how you interpret each cluster.\n",
    "- Write your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your import statement\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster import KMeansClusterer,cosine_distance,euclidean_distance\n",
    "from sklearn import mixture\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Would you rather get a gift that you knew what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is the internet ruining people's ability to co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Permanganate?\\nSuppose permanganate was used t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If Rock-n-Roll is really the work of the devil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Has anyone purchased software to watch TV on y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Would you rather get a gift that you knew what...\n",
       "1  Is the internet ruining people's ability to co...\n",
       "2  Permanganate?\\nSuppose permanganate was used t...\n",
       "3  If Rock-n-Roll is really the work of the devil...\n",
       "4  Has anyone purchased software to watch TV on y..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"hw6_train.csv\")\n",
    "train_text=train[\"text\"]\n",
    "\n",
    "test = pd.read_csv(\"hw6_test.csv\")\n",
    "test_label = test[\"label\"]\n",
    "test_text = test[\"text\"]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmean(train_text, test_text, test_label):\n",
    "    \n",
    "    \n",
    "    tfidf_v = TfidfVectorizer(stop_words=\"english\",min_df=3)\n",
    "    \n",
    "    dtm = tfidf_v.fit_transform(list(train_text)+list(test_text))\n",
    "    \n",
    "    num_clusters=4\n",
    "    \n",
    "    clust = KMeansClusterer(num_clusters, cosine_distance, repeats=20)\n",
    "    \n",
    "    clusters = clust.cluster(dtm.toarray(), assign_clusters=True)\n",
    "    \n",
    "    data = pd.DataFrame({\"Actual\":test_label,\"Cluster\":clusters[len(list(train_text)):]})\n",
    "\n",
    "    conf_matrix = pd.crosstab( index = data.Cluster, columns = data.Actual)\n",
    "    \n",
    "    matrix = conf_matrix.idxmax(axis=1)\n",
    "    \n",
    "    predicted_target = [matrix[i] for i in clusters[len(list(train_text)):]]\n",
    "    \n",
    "    best_report = metrics.classification_report(test_label, predicted_target)                      \n",
    "                    \n",
    "    print(best_report)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.77      0.76       332\n",
      "           2       0.89      0.70      0.78       314\n",
      "           3       0.74      0.83      0.79       355\n",
      "           7       0.69      0.74      0.72       273\n",
      "\n",
      "    accuracy                           0.76      1274\n",
      "   macro avg       0.77      0.76      0.76      1274\n",
      "weighted avg       0.77      0.76      0.76      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_kmean(train_text, test_text, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Clustering by Gaussian Mixture Model\n",
    "\n",
    "In this task, you'll re-do the clustering using a Gaussian Mixture Model. Call this function  `cluster_gmm(train_text, test_text, text_label)`. \n",
    "\n",
    "You may take a subset from the data to do GMM because it can take a lot of time. \n",
    "\n",
    "Write your analysis on the following:\n",
    "- How did you pick the parameters such as the number of clusters, variance type etc.?\n",
    "- Compare to Kmeans in Q1, do you achieve better preformance by GMM? \n",
    "\n",
    "- Note, like KMean, be sure to use different initial means (i.e. `n_init` parameter) when fitting the model to achieve the model stability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_gmm(train_text, test_text, test_label):\n",
    "    \n",
    "    trial=train[0:1500]\n",
    "    \n",
    "    tfidf_vect = TfidfVectorizer(stop_words=\"english\",min_df=5)\n",
    "    \n",
    "    dtm = tfidf_vect.fit_transform(list(trial)+list(test_text))\n",
    "    \n",
    "    num_clusters=4\n",
    "    lowest_bic = np.infty   \n",
    "    \n",
    "    best_gmm = None\n",
    "    \n",
    "    num_components = 4\n",
    "    \n",
    "    cv_types = ['spherical', 'tied', 'diag'] \n",
    "    \n",
    "    for cv_type in cv_types:\n",
    "    \n",
    "        for n_components in range(1,num_components+1):\n",
    "        \n",
    "            gmm = mixture.GaussianMixture(n_components=n_components,\n",
    "                                      n_init=3,\n",
    "                                      covariance_type=cv_type, random_state=5)\n",
    "            gmm.fit(dtm.toarray())\n",
    "            \n",
    "            bic = gmm.bic(dtm.toarray())  \n",
    "        \n",
    "            if bic < lowest_bic:  \n",
    "                lowest_bic = bic\n",
    "                best_gmm = gmm\n",
    "        \n",
    "    predicted = best_gmm.predict(dtm.toarray())\n",
    "    \n",
    "    data2 = pd.DataFrame({\"Actual\":test_label,\"Predicted\":predicted[len(list(trial)):]})\n",
    "    \n",
    "    confusion_matrix1 = pd.crosstab(index=data2.Predicted, columns=data2.Actual)\n",
    "    \n",
    "    matrix2 = confusion_matrix1.idxmax(axis=1)\n",
    "    \n",
    "    predicted_targ = [matrix2[i] for i in predicted[len(list(trial)):]]\n",
    "    \n",
    "    best_report = metrics.classification_report(test_label, predicted_targ)\n",
    "                    \n",
    "    print(best_report)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.66      0.72       332\n",
      "           2       0.65      0.84      0.73       314\n",
      "           3       0.81      0.68      0.74       355\n",
      "           7       0.72      0.75      0.74       273\n",
      "\n",
      "    accuracy                           0.73      1274\n",
      "   macro avg       0.74      0.73      0.73      1274\n",
      "weighted avg       0.74      0.73      0.73      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_gmm(train_text, test_text, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Clustering by LDA \n",
    "\n",
    "In this task, you'll re-do the clustering using LDA. Call this function `cluster_lda(train_text, test_text, text_label)`. \n",
    "\n",
    "However, since LDA returns topic mixture for each document, you `assign the topic with highest probability to each test document`, and then measure the performance as in Q1\n",
    "\n",
    "In addition, within the function, please print out the top 30 words for each topic\n",
    "\n",
    "Finally, please analyze the following:\n",
    "- Based on the top words of each topic, could you assign a meaningful name to each topic?\n",
    "- Although the test subset shows there are 4 clusters, without this information, how do you choose the number of topics? \n",
    "- Does your LDA model achieve better performance than KMeans or GMM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_lda(train, test_text, test_label):\n",
    "    \n",
    "    stop = list(stopwords.words('english')) + ['said']\n",
    "    \n",
    "    tf_vec = CountVectorizer(stop_words = stop,min_df = 5)\n",
    "    \n",
    "    tf = tf_vec.fit_transform(list(train) + list(test_text))\n",
    "    \n",
    "    tf_feature = tf_vec.get_feature_names()\n",
    "    \n",
    "    num_clusters = 4\n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_components = num_clusters, evaluate_every = 1, max_iter = 40, verbose = 1, n_jobs = 1, random_state = 5).fit(tf[0:len(train)])\n",
    "\n",
    "    topic_assgn = lda.transform(tf[len(train):])\n",
    "    \n",
    "    topic = topic_assgn.argmax(axis = 1)\n",
    "    \n",
    "    data = pd.DataFrame({\"Actual\":test_label,\"Topic\":topic})\n",
    "    \n",
    "    confusion_matrix = pd.crosstab(index = data.Topic, columns = data.Actual)\n",
    "    \n",
    "    matrix3 = confusion_matrix.idxmax(axis = 1)\n",
    "    \n",
    "    predicted_target1 = [matrix3[i] for i in topic]\n",
    "    \n",
    "    topic_top_words = 30\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        words = [(tf_feature[i],'%.2f'%topic[i]) \\\n",
    "           for i in topic.argsort()[::-1][0:topic_top_words]]\n",
    "        print(words)\n",
    "     \n",
    "                \n",
    "    print(metrics.classification_report(test_label, predicted_target1,labels=np.unique(predicted_target1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshulreddy/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 40, perplexity: 3479.8162\n",
      "iteration: 2 of max_iter: 40, perplexity: 3278.1892\n",
      "iteration: 3 of max_iter: 40, perplexity: 3137.3244\n",
      "iteration: 4 of max_iter: 40, perplexity: 3005.9137\n",
      "iteration: 5 of max_iter: 40, perplexity: 2891.8078\n",
      "iteration: 6 of max_iter: 40, perplexity: 2808.4982\n",
      "iteration: 7 of max_iter: 40, perplexity: 2749.4345\n",
      "iteration: 8 of max_iter: 40, perplexity: 2707.6550\n",
      "iteration: 9 of max_iter: 40, perplexity: 2677.8232\n",
      "iteration: 10 of max_iter: 40, perplexity: 2656.1646\n",
      "iteration: 11 of max_iter: 40, perplexity: 2639.6492\n",
      "iteration: 12 of max_iter: 40, perplexity: 2626.3126\n",
      "iteration: 13 of max_iter: 40, perplexity: 2615.4187\n",
      "iteration: 14 of max_iter: 40, perplexity: 2607.2094\n",
      "iteration: 15 of max_iter: 40, perplexity: 2600.8870\n",
      "iteration: 16 of max_iter: 40, perplexity: 2595.9996\n",
      "iteration: 17 of max_iter: 40, perplexity: 2591.5784\n",
      "iteration: 18 of max_iter: 40, perplexity: 2587.6067\n",
      "iteration: 19 of max_iter: 40, perplexity: 2584.5958\n",
      "iteration: 20 of max_iter: 40, perplexity: 2582.1188\n",
      "iteration: 21 of max_iter: 40, perplexity: 2580.2126\n",
      "iteration: 22 of max_iter: 40, perplexity: 2578.5690\n",
      "iteration: 23 of max_iter: 40, perplexity: 2577.0850\n",
      "iteration: 24 of max_iter: 40, perplexity: 2575.8254\n",
      "iteration: 25 of max_iter: 40, perplexity: 2574.7116\n",
      "iteration: 26 of max_iter: 40, perplexity: 2573.7108\n",
      "iteration: 27 of max_iter: 40, perplexity: 2572.8234\n",
      "iteration: 28 of max_iter: 40, perplexity: 2571.9997\n",
      "iteration: 29 of max_iter: 40, perplexity: 2571.2409\n",
      "iteration: 30 of max_iter: 40, perplexity: 2570.4930\n",
      "iteration: 31 of max_iter: 40, perplexity: 2569.7867\n",
      "iteration: 32 of max_iter: 40, perplexity: 2569.0904\n",
      "iteration: 33 of max_iter: 40, perplexity: 2568.4255\n",
      "iteration: 34 of max_iter: 40, perplexity: 2567.6848\n",
      "iteration: 35 of max_iter: 40, perplexity: 2566.7994\n",
      "iteration: 36 of max_iter: 40, perplexity: 2565.8153\n",
      "iteration: 37 of max_iter: 40, perplexity: 2564.6982\n",
      "iteration: 38 of max_iter: 40, perplexity: 2563.5624\n",
      "iteration: 39 of max_iter: 40, perplexity: 2562.4463\n",
      "iteration: 40 of max_iter: 40, perplexity: 2561.3276\n",
      "Topic 0:\n",
      "[('people', '1241.03'), ('god', '1030.23'), ('would', '742.53'), ('one', '700.58'), ('think', '699.90'), ('like', '680.80'), ('know', '597.22'), ('life', '528.42'), ('us', '414.40'), ('say', '411.13'), ('believe', '395.22'), ('time', '389.91'), ('many', '355.70'), ('jesus', '350.25'), ('way', '341.82'), ('world', '338.18'), ('person', '328.59'), ('love', '325.27'), ('good', '323.22'), ('want', '318.79'), ('really', '317.29'), ('bible', '315.14'), ('man', '310.60'), ('even', '304.10'), ('get', '294.48'), ('question', '287.57'), ('see', '286.56'), ('things', '284.76'), ('make', '274.87'), ('religion', '271.25')]\n",
      "Topic 1:\n",
      "[('get', '895.52'), ('like', '692.27'), ('help', '614.20'), ('body', '525.77'), ('one', '488.40'), ('also', '483.87'), ('go', '457.98'), ('know', '445.17'), ('weight', '428.32'), ('would', '413.08'), ('take', '409.62'), ('time', '404.86'), ('may', '404.19'), ('good', '395.63'), ('could', '378.18'), ('need', '376.76'), ('doctor', '361.24'), ('day', '355.84'), ('really', '353.80'), ('blood', '351.25'), ('eat', '334.39'), ('feel', '316.25'), ('much', '315.28'), ('make', '311.79'), ('back', '295.81'), ('people', '289.84'), ('see', '289.57'), ('want', '287.45'), ('pain', '284.42'), ('use', '283.78')]\n",
      "Topic 2:\n",
      "[('water', '454.12'), ('one', '374.83'), ('would', '357.87'), ('nthe', '337.79'), ('energy', '286.37'), ('light', '266.04'), ('earth', '262.98'), ('10', '262.02'), ('number', '252.29'), ('two', '240.38'), ('air', '232.66'), ('also', '213.24'), ('used', '212.52'), ('time', '179.65'), ('mass', '176.34'), ('first', '169.49'), ('answer', '165.32'), ('gas', '156.05'), ('many', '155.90'), ('like', '150.44'), ('force', '149.50'), ('na', '146.28'), ('speed', '146.03'), ('see', '145.26'), ('sun', '144.78'), ('different', '137.14'), ('know', '136.92'), ('space', '135.42'), ('find', '134.49'), ('equation', '132.23')]\n",
      "Topic 3:\n",
      "[('get', '608.64'), ('com', '605.23'), ('www', '484.23'), ('want', '425.23'), ('good', '425.04'), ('nhttp', '412.59'), ('would', '408.51'), ('need', '401.57'), ('work', '375.92'), ('business', '370.24'), ('one', '370.19'), ('money', '355.98'), ('job', '335.92'), ('help', '335.34'), ('find', '327.68'), ('know', '310.69'), ('like', '278.49'), ('make', '271.35'), ('credit', '265.25'), ('go', '259.24'), ('pay', '257.99'), ('http', '245.57'), ('time', '238.58'), ('company', '227.67'), ('also', '213.15'), ('question', '207.82'), ('information', '206.17'), ('way', '197.58'), ('yahoo', '197.42'), ('may', '196.44')]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.87      0.81       332\n",
      "           2       0.95      0.68      0.79       314\n",
      "           3       0.80      0.83      0.81       355\n",
      "           7       0.72      0.78      0.75       273\n",
      "\n",
      "    accuracy                           0.79      1274\n",
      "   macro avg       0.80      0.79      0.79      1274\n",
      "weighted avg       0.81      0.79      0.79      1274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_lda(train_text, test_text, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 (Bonus): Word vectors\n",
    "\n",
    "Write a function `train_wordvec(docs, vector_size)` as follows:\n",
    "- Take two inputs:\n",
    "    - `docs`: a list of documents\n",
    "    - `vector_size`: the dimension of word vectors\n",
    "- First tokenize `docs` into tokens\n",
    "- Use `gensim` package to train word vectors. Set the `vector size` and also carefully set other parameters such as `window`, `min_count` etc.\n",
    "- return the trained word vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk,string\n",
    "from gensim.models import word2vec\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use a different dataset\n",
    "train = pd.read_csv(\"hw7_train.csv\")\n",
    "test = pd.read_csv(\"hw7_test.csv\")\n",
    "# let's just use a sample for testing\n",
    "test=test[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wordvec(docs, vector_size):\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    # add your code here\n",
    "    \n",
    "    return wv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call yoor function\n",
    "wv_model = train_wordvec(train[\"text\"], vector_size = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write a function `generate_doc_vector(docs, wv_model)` as follows:\n",
    "- Take two inputs:\n",
    "    - `docs`: a list of documents, \n",
    "    - `wv_model`: trained word vector model. \n",
    "- First tokenize each document `doc` in `docs` into tokens\n",
    "- For each token in `doc`, look up for its word vector in `wv_model`. Then the document vector (denoted as `d`) of `doc` can be calculated as the `mean of the word vectors of its tokens`, i.e. $d = \\frac{\\sum_{i \\in doc}{v_i}}{|doc|}$, where $v_i$ is the word vector of the i-th token.\n",
    "- Return the vector representations `vectors` of all `docs` as a numpy array of shape `(n, vector_size)`, where `n` is the number of documents in `docs` and `vector_size` is the dimension of word vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_doc_vector(docs, wv_model):\n",
    "    \n",
    "    vectors = None\n",
    "    \n",
    "    # add your code here\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get vectors\n",
    "\n",
    "train_X = generate_doc_vector(train[\"text\"], wv_model)\n",
    "test_X = generate_doc_vector(test[\"text\"], wv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       237\n",
      "           1       0.78      0.75      0.77       263\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.76      0.76      0.76       500\n",
      "weighted avg       0.76      0.76      0.76       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#fit a svm model\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.LinearSVC().fit(train_X, train[\"label\"])\n",
    "predicted=clf.predict(test_X)\n",
    "print(classification_report\\\n",
    "      (test[\"label\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
